{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Scraping\n",
    "\n",
    "In this notebook I made a simple scraper for Wikipedia. The data from the scraper is used to plot a network graph in which the relation between different subjects is visualised.\n",
    "\n",
    "This excercise served as a practice for the BeautifulSoup library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_soup(search_string):\n",
    "    '''gets the html of the relevant wikipedia page and returns a BeautifulSoup object'''\n",
    "    search_string = search_string.replace(\" \", \"_\")\n",
    "    response = requests.get(f\"https://en.wikipedia.org/wiki/{search_string}\")\n",
    "    source = response.content\n",
    "    soup = BeautifulSoup(source, \"html.parser\")\n",
    "    \n",
    "    return soup\n",
    "\n",
    "def extract_soup(soup):\n",
    "    '''extracts all the titles of links in the wikipedia paragraphs'''\n",
    "    subjects = [i[\"title\"] for i in soup.select(\"p a[title]\")]\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "def create_graph(search_string, subjects, nx_graph = None):\n",
    "    '''creates a graph and adds nodes and edges between the search string and subjects\n",
    "    if a nx_graph is given, nodes and edges will be added to the given graph'''\n",
    "    if nx_graph is None:\n",
    "        nx_graph = nx.Graph()\n",
    "        nx_graph.add_node(search_string, size=20)\n",
    "    \n",
    "    for title in subjects:\n",
    "        nx_graph.add_node(title, size=5)\n",
    "        nx_graph.add_edge(search_string, title, weight=5)\n",
    "        \n",
    "    return nx_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_string = \"Web scraping\"\n",
    "\n",
    "soup = search_and_soup(search_string)\n",
    "#100 is set as the maximum of first order relations to show\n",
    "subjects = subjects[:min(100, len(subjects))]\n",
    "subjects = extract_soup(soup)\n",
    "nx_graph = create_graph(search_string, subjects)\n",
    "\n",
    "#50 subjects to be explored on relations is set as maximum\n",
    "for search_string in subjects[:min(50, len(subjects))]:\n",
    "    soup = search_and_soup(search_string)\n",
    "    subjects2 = extract_soup(soup)\n",
    "    #10 is set as the maximum of second order relations to show\n",
    "    subjects2 = subjects2[:min(10, len(subjects2))]\n",
    "    nx_graph = create_graph(search_string, subjects2, nx_graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000px\"\n",
       "            height=\"1000px\"\n",
       "            src=\"nx.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1910d3f0940>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graph physics settings\n",
    "options = 'var options = {\"physics\": { \"enabled\": true, \"barnesHut\": {\"springLength\": 100},\"minVelocity\": 1,\"solver\": \"forceAtlas2Based\",\"timestep\": 0.61}}'\n",
    "nt = Network(\"1000px\", \"1000px\", notebook = True)\n",
    "# populates the nodes and edges data structures\n",
    "nt.from_nx(nx_graph)\n",
    "nt.set_options(options)\n",
    "nt.show(\"nx.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
